{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, requests\n",
    "import pandas as pd\n",
    "#url = 'https://api.foursquare.com/v2/venues/VENUE_ID/listed'\n",
    "#url = 'https://api.foursquare.com/v2/venues/explore'\n",
    "url = 'https://api.foursquare.com/v2/venues/search'\n",
    "\n",
    "params = dict(\n",
    "  client_id='',  # input client id and client secret\n",
    "  client_secret='',\n",
    "  v='20190819',\n",
    "  ll='1.335572,103.965142',\n",
    "  #radius=2000, \n",
    "  sw = '1.331747, 103.961258',\n",
    "  ne = '1.339397, 103.969027',  \n",
    "  #VENUE_ID='HZXXY3Y',\n",
    "  #intent = 'browse',  \n",
    "  limit=2000\n",
    "  #query='coffee',\n",
    "  #limit=1\n",
    ")\n",
    "resp = requests.get(url=url, params=params)\n",
    "data1 = json.loads(resp.text)\n",
    "\n",
    "len(data1['response']['venues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_id = []\n",
    "name = []\n",
    "lat = []\n",
    "lng = []\n",
    "postcode = []\n",
    "address = []\n",
    "category = []\n",
    "for query in data1['response']['venues']:\n",
    "    list_id.append(query['id'])\n",
    "    name.append(query['name'])\n",
    "    lat.append(query['location']['lat'])\n",
    "    lng.append(query['location']['lng'])\n",
    "    #postcode.append(query['venue']['location']['postalCode'])\n",
    "    #postcode.append(query['venue']['location']['formattedAddress'][1])\n",
    "    #if query['location']['postalCode']:\n",
    "        #postcode.append(query['location']['postalCode'])\n",
    "    #else: postcode.append('')\n",
    "    address.append(query['location']['formattedAddress'])\n",
    "    if query['categories']: \n",
    "        category.append(query['categories'][0]['name'])\n",
    "    else: category.append('')\n",
    "    #category.append(query['categories'][0]['name'] if (len(query['categories'] > 0) else: ''))\n",
    "\n",
    "poi_data1 = pd.DataFrame({'id': list_id, \n",
    "                         'name': name,\n",
    "                         'lat': lat,\n",
    "                         'lng': lng,\n",
    "                         #'postcode': postcode,\n",
    "                         'address': address,\n",
    "                         'category': category})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_data1.to_csv('poi_try1_819.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OSM\n",
    "## manually export from overpass.turbo\n",
    "with open('export_sep_10_try3.geojson') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "list_id = []\n",
    "name = []\n",
    "lat = []\n",
    "lng = []\n",
    "postcode = []\n",
    "address = []\n",
    "category = []\n",
    "for query in data['features']:\n",
    "    list_id.append(query['id'])\n",
    "    #if query['properties']['name']: \n",
    "        #name.append(query['properties']['name'])\n",
    "    #else: name.append('')\n",
    "    try: name.append(query['properties']['name'])  \n",
    "    except: name.append('')\n",
    "    lat.append(query['geometry']['coordinates'][1])\n",
    "    lng.append(query['geometry']['coordinates'][0])\n",
    "    #postcode.append(query['venue']['location']['postalCode'])\n",
    "    #postcode.append(query['venue']['location']['formattedAddress'][1])\n",
    "    #if query['location']['postalCode']:\n",
    "        #postcode.append(query['location']['postalCode'])\n",
    "    #else: postcode.append('')\n",
    "    #address.append(query['location']['formattedAddress'])\n",
    "    if 'highway' in query['properties'].keys(): \n",
    "        category.append(query['properties']['highway'])\n",
    "    elif 'barrier' in query['properties'].keys(): \n",
    "        category.append(query['properties']['barrier'])\n",
    "    elif 'shop' in query['properties'].keys(): \n",
    "        category.append(query['properties']['shop'])\n",
    "    elif 'public_transport' in query['properties'].keys(): \n",
    "        category.append(query['properties']['public_transport'] + '(public_transport)')\n",
    "    elif 'amenity' in query['properties'].keys(): \n",
    "        category.append(query['properties']['amenity'])\n",
    "    elif 'place' in query['properties'].keys(): \n",
    "        category.append(query['properties']['place'])\n",
    "    elif 'station' in query['properties'].keys(): \n",
    "        category.append(query['properties']['station'] + '_station')\n",
    "    elif 'building' in query['properties'].keys(): \n",
    "        category.append(query['properties']['building'])\n",
    "    elif 'tourism' in query['properties'].keys(): \n",
    "        category.append(query['properties']['tourism'])\n",
    "    elif 'office' in query['properties'].keys():\n",
    "        if query['properties']['office'] == 'yes': \n",
    "            category.append('office')\n",
    "    elif 'railway' in query['properties'].keys(): \n",
    "        category.append(query['properties']['railway'] + '(railway)') # overlap with public transport?\n",
    "    elif 'crossing' in query['properties'].keys(): \n",
    "        category.append(query['properties']['crossing'])\n",
    "    elif 'natural' in query['properties'].keys(): \n",
    "        category.append(query['properties']['natural'])\n",
    "    elif 'location' in query['properties'].keys(): \n",
    "        category.append(query['properties']['location'])\n",
    "    elif 'leisure' in query['properties'].keys(): \n",
    "        category.append(query['properties']['leisure'])\n",
    "    elif 'aeroway' in query['properties'].keys(): \n",
    "        category.append(query['properties']['aeroway'] + '(aeroway)')\n",
    "    elif 'entrance' in query['properties'].keys(): \n",
    "        if query['properties']['entrance'] == 'yes': \n",
    "            category.append('entrance')\n",
    "            \n",
    "    else: category.append('')\n",
    "    #category.append(query['categories'][0]['name'] if (len(query['categories'] > 0) else: ''))\n",
    "\n",
    "poi_data = pd.DataFrame({'id': list_id, \n",
    "                         'name': name,\n",
    "                         'lat': lat,\n",
    "                         'lng': lng,\n",
    "                         #'postcode': postcode,\n",
    "                         #'address': address,\n",
    "                         'category': category})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poi_data.merge(poi_data3, on = ['lat','lng'], how = 'inner')\n",
    "#poi_data3['lat'] = poi_data3['lat'].apply(lambda x: round(x,6))\n",
    "#poi_data3['lng'] = poi_data3['lng'].apply(lambda x: round(x,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-Levenshtein\n",
    "import Levenshtein\n",
    "import distance\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "#similar('Xilin', 'Xilinx Building')\n",
    "#Levenshtein.ratio('Xilin', 'Xilinx Building')\n",
    "#1-distance.jaccard('Xilin', 'Xilinx Building')\n",
    "#fuzz.ratio('Xilin', 'Xilinx Building')\n",
    "#fuzz.token_sort_ratio('Xilin', 'Xilinx Building')\n",
    "#fuzz.token_set_ratio('Xilin', 'Xilinx Building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_latlon_and_name(name, lat, lon, df2, min_score=0, dist_thres=0.03):\n",
    "    # -1 score incase we don't get any matches\n",
    "    max_score = -1\n",
    "    # Returning empty name for no match as well\n",
    "    max_name = \"\"\n",
    "    max_lat = \"\"\n",
    "    max_lon = \"\"\n",
    "    # Iternating over all names in the other\n",
    "    for row in df2.iterrows():\n",
    "        name2 = row[1][1]\n",
    "        lat2 = row[1][2]\n",
    "        lon2 = row[1][3]\n",
    "        #Finding fuzzy match score\n",
    "        score = fuzz.ratio(name, name2)\n",
    "        # Checking if we are above our threshold and have a better score\n",
    "        if (score > min_score) & (score > max_score) & (haversine(lon, lat, lon2, lat2) < dist_thres) & (score<100):\n",
    "            max_name = name2\n",
    "            max_lat = lat2\n",
    "            max_lon = lon2\n",
    "            max_score = score\n",
    "    return (max_name, max_lat, max_lon, max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list = []\n",
    "# iterating over our players without salaries found above\n",
    "for row in poi_data3.iterrows():\n",
    "    name = row[1][1]\n",
    "    lat = row[1][2]\n",
    "    lon = row[1][3]\n",
    "    # Use our method to find best match, we can set a threshold here\n",
    "    match = match_latlon_and_name(name, lat, lon, poi_data, 55, 0.1)\n",
    "    \n",
    "    # New dict for storing data\n",
    "    dict_ = {}\n",
    "    dict_.update({\"foursquare_name\" : name})\n",
    "    dict_.update({\"foursquare_lat\" : lat})\n",
    "    dict_.update({\"foursquare_lon\" : lon})\n",
    "    dict_.update({\"osm_name\" : match[0]})\n",
    "    dict_.update({\"osm_lat\" : match[1]})\n",
    "    dict_.update({\"osm_lon\" : match[2]})\n",
    "    dict_.update({\"score\" : match[3]})\n",
    "    dict_list.append(dict_)\n",
    "    \n",
    "merge_table = pd.DataFrame(dict_list)\n",
    "# Display results\n",
    "merge_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
